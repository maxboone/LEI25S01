\section{Text Categorization}

We can separate classification tasks in three distinct
categories: binary classification (yes/no), multi-class
classification (a/b/c) and multi-label
classification (nil/a/a,b/...).

\subsection{Task Definition}

\paragraph{Text Unit}

First define the text unit, i.e. the size and boundary
of the document. For example, complete documents (articles,
emails), sections (minutes, speeches) or sentences (language
identification, sentiment classification).

\paragraph{Categories}

What is the category that we want to extract from the documents,
i.e. spam/no spam, relevant/irrelevant, language, sentiment, stance,
topic/subtopic (i.e. which type of cancer), warning (i.e. detect hate
speech).

\paragraph{Pre-processing}

We want to have features for documents, for example a vector
from each document with the same dimensionality. Using the bag
of words you would have a high-dimensional vector that is very
sparse, the advantage is that it is very transparent and you can
show from the weights why a classifier learned a specific model.
Alternatively, you can use embeddings which is less interpretable.


