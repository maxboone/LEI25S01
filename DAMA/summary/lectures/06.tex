\section{Subgroup Discovery}

Compared to a global model, we are sometimes interested
in training local patterns, which are models that cover
only part of the data.

For example, a prediction rule
where we have a model that only holds for the left-hand
side could be:

\begin{align*}
  \text{status} =
  \text{married} \cap \text{age} >= 29 \rightarrow
  \text{salary} \geq 50000
\end{align*}

The complement can be the same or different. The main idea
is that we can do exploratory data analysis and find dependencies
in attributes and create a global model that has little overlap
and resolves conflicts.

\begin{definition}[Subgroup]
  Subset of the data with unusual charactersitics (antecedent of a rule).
\end{definition}

Subgroup Discovery is a supervised paradigm, where we can do
classification where the target is binary or nominal or regression
where the target is numeric. Alternatively, there's EMM, where we
have different kinds of targets.

For example, if we have a binary target such as whether something
is in a subgroup, we can draw a confusion matrix.

\begin{definition}[Confusion Matrix]
  \[
    \begin{array}{c|c|c|c}
      & \textbf{T} & \textbf{F} & \\ \hline
      \textbf{T} & TP & FP & TP + FP \\ \hline
      \textbf{F} & FN & TN & FN + TN \\ \hline
      & TP + FN & FP + TN & Total \\
    \end{array}
  \]

  \textbf{Significance of Diagonal Values:} High values on the
  True Positive and True Negative means there is a positive
  correlation. High values on the False Positive and False Negative
  means there is a negative correlation.
\end{definition}

\subsection{Quality Measures}

A quality measure for subgroups summarizes the interestingness
of the matrix into a single number. While the quality measures
increase the interestingness of the subgroup, the coverage of
the subgroup might be worse.

\subsubsection{Receiver Operating Characteristics (ROC)}

Each subgroup forms a point in the ROC space, in terms of its
false positive rate and true positive rate.

\begin{definition}[True/False Postive Rate]
  \begin{align*}
    TPR &= \frac{TP}{TP + FP} \\
    FPR &= \frac{FP}{FP + TN}
  \end{align*}
\end{definition}

Ideally, you have both these ratios very high or low, if we
graph them in a space then the diagonal is as good as random
and the left-top and bottom-right corner are perfect subgroups.
the left-bottom and top-right corner are either an empty subgroup
or the entire database.

Refining the subgroup inside the ROC-space means that you can only
go down or to the left as it gets smaller.

\subsubsection{WRAcc}

A simple quality measure is the weighted relative accuracy.

\begin{definition}[Weighted Relative Accuracy (WRAcc)]
  \begin{displaymath}
    \text{WRAcc}(A, B) = p(AB) - p(A)p(B)
  \end{displaymath}

  Balance between coverage, from the confusion matrix
  above this would be $TT - (TT + TF)(TT + FT)$ and is
  interesting around 0, and a range between $-.25$ to $.25$
\end{definition}

The WRAcc increases towards the top-left ROC space and decreases
towards the bottom-right ROC space. It is additive for non-overlapping
subgroups, and its isometrics are linear and parallel to the main
diagonal.

\begin{definition}[Cortana Quality]
  An extension to the WRAcc is the Cortana Quality, which ensures that
  the WRAcc scores are between -1 and 1. $\varphi_{cq}(S) = \alpha \times
  \varphi_{w}(S)$ and $\alpha$ is constant per dataset.
\end{definition}

\subsection{Numeric Subgroup Discovery}

Instead of a binary target, we might have a numeric target. The idea is
that we find subgroups with a significantly higher or lower average value.
The trade-off is the size of the subgroup and the average target value.

Some quality measures are:

\begin{definition}[Average]
  \begin{align*}
    \varphi_{avg}(s) = \frac{\sum^n_{i=1}t_i}{n}
  \end{align*}
\end{definition}

Note that the average doesn't take the size into account
of the subgroup, the following measures do:

\begin{definition}[Mean Test]
  \begin{align*}
    \varphi_{mt}(s) = \sqrt{n}(\mu - \mu_0)
  \end{align*}
\end{definition}

\begin{definition}[z-score]
  \begin{align*}
    \varphi_{z}(s) = \frac{\mu - \mu_0}{\sigma_0/\sqrt{n}}
    = \frac{\sqrt{n}(\mu - \mu_0)}{\sigma_0}
  \end{align*}
\end{definition}

\begin{definition}[t-Statistic]
  \begin{align*}
    \varphi_{t}(s) = \frac{\mu - \mu_0}{\sigma/\sqrt{n}}
  \end{align*}
\end{definition}

\subsection{Exceptional Model Mining}

SubDisc (formerly Cortana) does classical subgroup discovery
as in nominal or numeric targets. But it also does Exceptional
Model Mining, where there are multiple targets such as regression,
correlation and multi-label classification.

For example, we have a distribution that clearly contains a linear
model but also a lot of background noise. We want to extract the
data points that regress well and do another model on the other
data.

\subsubsection{Quality Measures}

\paragraph{Correlation Model}
\begin{itemize}
  \item \textbf{Correlation coefficient}:
    \begin{align*}
      \varphi_\rho = \rho(S)
    \end{align*}
  \item \textbf{Absolute difference in correlation}:
    \begin{align*}
      \varphi_{abs} = | \rho(S) - \rho(S_0) |
    \end{align*}
  \item \textbf{Entropy weighted absolute difference}:
    \begin{align*}
      \varphi_{ent} = H(p) \cdot | \rho(S) - \rho(S_0) |
    \end{align*}
  \item \textbf{Statistical significance of correlation difference}:
    \begin{itemize}
      \item Compute z-score from \( \rho \) through Fisher transformation.
      \item Compute p-value from z-score.
    \end{itemize}
\end{itemize}

\paragraph{Regression Model}
\begin{itemize}
  \item Compare slope \( b \) of
    \begin{align*}
      y_i = a + b \cdot x_i \quad \text{and} \quad y_i = a_0 + b_0 \cdot x_i
    \end{align*}
  \item Compute significance of slope difference:
    \begin{align*}
      \varphi_{ssd} = \frac{b - b_0}{\text{Standard Error of } b}
    \end{align*}
\end{itemize}

